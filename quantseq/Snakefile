# Quantseq pipeline
# A. M. Chakrabarti
# 13th May 2019, revised 15th January 2021

# sbatch -N 1 -J quantseq -t 48:00:00 -o quantseq_%A.out --wrap="time snakemake -k --cluster 'sbatch {params.cluster}' --jobs 200 --latency-wait 60"

# Import config file & parameters
configfile: 'config.yaml'

# ==========
# Endgame
# ==========

rule all:
    input:
        expand("results/counts/{sample}.polyacount.bed.gz", sample=config["samples"]),
        expand("results/drimseq/{mutant}.d.rds", mutant=config["mutants"]),
        "results/quantseq_report.html",

# ==========
# Preprocessing steps
# ==========

rule fastqc:
    input:
        lambda wildcards: config["samples"][wildcards.sample]
    output:
        html="results/fastqc/{sample}_fastqc.html",
        fczip=temp("results/fastqc/{sample}_fastqc.zip")
    params:
        fc="--outdir results/fastqc",
        cluster="-J fastqc -N 1 --mem=16G -t 12:00:00 -o logs/fastqc.{sample}.%A.log"
    run:
        shell("fastqc {input} {params.fc}")
        fastqc_out = "/".join(("results/fastqc", os.path.basename(input[0])))
        fastqc_out = "_".join((fastqc_out, "fastqc.html"))
        fastqc_out = fastqc_out.replace(".fastq.gz","")
        shell("echo {fastqc_out}")
        shell("mv {fastqc_out} {output.html}")

# Remove adapters
rule cutadapt:
    input:
        lambda wildcards: config["samples"][wildcards.sample]
    output:
        "results/cutadapt/{sample}_trimmed.fastq.gz",
    params:
        log="results/cutadapt/{sample}_trimming_report.txt",
        cluster="-J cutadapt -N 1 -c 8 --mem=16G -t 12:00:00 -o logs/cutadapt.{sample}.%A.log"
    threads:
        8
    shell:
        """
        cutadapt -j {threads} -q 10 -m 18 -a AGATCGGAAGAGC -o {output} {input}
        """

# ==========
# Poly A read processing
# ==========

# Get polyA reads
# Select those with AAAAA at the end
# Then trim off the polyA tail and also the 5' 12 nucleotides (as recommended for Quantseq)

rule getpolyAreads:
    input:
        # fastq="results/trim_galore/{sample}_trimmed.fastq.gz"
        fastq="results/cutadapt/{sample}_trimmed.fastq.gz"
    output:
        polyAfastq=temp("results/polya/{sample}.polya.fastq.gz"),
        polyAtrimmedfastq="results/polya/{sample}.polya.trimmed.fastq.gz",
        nopolyAfastq="results/polya/{sample}.nopolya.fastq.gz"
    params:
        cluster="-J getpolyAreads -N 1 -c 8 --mem-per-cpu=2G -t 24:00:00 -o logs/getpolyAreads.{sample}.%A.log"
    threads:
        8
    shell:
        """
        cutadapt -j {threads} --no-indels -e 0 -O 5 -a "AAAAA$" --no-trim --untrimmed-output {output.nopolyAfastq} -o {output.polyAfastq} {input.fastq}
        cutadapt -j {threads} -m 18 --cut 12 --no-indels -e 0 -a "A{{1000}}" -o {output.polyAtrimmedfastq} {output.polyAfastq}
        """

# Map to genome and index
# Currently only keeping uniquely mapped reads

rule polyAmapstar:
    input:
        fastq="results/polya/{sample}.polya.trimmed.fastq.gz"
    output:
        bam="results/polya_mapped/{sample}.Aligned.sortedByCoord.out.bam",
        bai="results/polya_mapped/{sample}.Aligned.sortedByCoord.out.bam.bai",
    params:
        star_index=config['star_index'],
        outprefix="results/polya_mapped/{sample}.",
        cluster="-J polyAmapstar -N 1 -c 8 --mem-per-cpu=6GB -t 24:00:00 -o logs/polyAmapstar.{sample}.%A.log"
    threads:
        8
    shell:
        """
        STAR --runThreadN {threads} \
        --genomeDir {params.star_index} --genomeLoad NoSharedMemory \
        --readFilesIn {input.fastq} --readFilesCommand zcat \
        --outFileNamePrefix {params.outprefix} \
        --sjdbScore 1 --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 \
        --outFilterMultimapNmax 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 \
        --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 \
        --outFilterType BySJout --twopassMode Basic \
        --outSAMattributes All --outSAMstrandField intronMotif \
        --outSAMtype BAM SortedByCoordinate --limitBAMsortRAM 60000000000

        samtools index -@ {threads} {output.bam}
        """

# Function to define combined input for merge rule
def polyAcoverage_inputs(wildcards):
    files = expand("results/polya_mapped/{sample}.Aligned.sortedByCoord.out.bam", sample = config["samples"])
    return files

# Merge all polyA ends
rule polyAcoverage:
    input:
        polyAcoverage_inputs
    output:
        bam=temp("results/polya_mapped/merged/polyAclusters.bam"),
        bg_pos="results/polya_mapped/merged/polyAclusters.pos.bedgraph",
        bg_neg="results/polya_mapped/merged/polyAclusters.neg.bedgraph"
    params:
        fai=config['fai'],
        cluster="-J polyAcoverage -N 1 -c 8 --mem=16G -t 12:00:00 -o logs/polyAcoverage.%A.log"
    shell:
        """
        samtools merge -t 8 {output.bam} {input}
        bedtools genomecov -bg -strand + -3 -ibam {output.bam} -g {params.fai} > {output.bg_pos}
        bedtools genomecov -bg -strand - -3 -ibam {output.bam} -g {params.fai} > {output.bg_neg}
        """

# Filter random priming artefacts
rule removeRandomPriming:
    input:
        bg_pos="results/polya_mapped/merged/polyAclusters.pos.bedgraph",
        bg_neg="results/polya_mapped/merged/polyAclusters.neg.bedgraph"
    output:
        bed="results/mergedclusters/polyAclusters.bed",
        uniquebed="results/mergedclusters/polyAclusters.unique.bed",
    params:
        randomprimingscript=config['randompriming'],
        minreads=config['minreads'],
        clusterdist=config['clusterdist'],
        pas=config['pas'],
        apa=config['apa'],
        nopas=config['nopas'],
        cluster="-J removeRandomPriming -N 1 -c 4 --mem=32G -t 12:00:00 -o logs/removeRandomPriming.%A.log"
    shell:
        """
        Rscript --vanilla {params.randomprimingscript} \
            --bg_pos {input.bg_pos} \
            --bg_neg {input.bg_neg} \
            --output {output.bed} \
            --minreads {params.minreads} \
            --clusterdist {params.clusterdist} \
            --pas {params.pas} \
            --apa {params.apa} \
            --nopas {params.nopas} \
            > results/mergedclusters/RemoveRandomPriming.rlog 2>&1
        """

# Annotate clusters with gene id
rule annotateFilteredClusters:
    input:
        "results/mergedclusters/polyAclusters.unique.bed",
    output:
        annotatedbed="results/mergedclusters/polyAclusters.unique.annotated.bed",
    log:
        "results/mergedclusters/AnnotatePolyAClusters.rlog"
    threads:
        8
    params:
        annotateclustersscript=config['annotateclusters'],
        gff3=config['gff3'],
        cluster="-J annotateFilteredClusters -N 1 -c 8 --mem=32G -t 12:00:00 -o logs/annotateFilteredClusters.%A.log"
    threads:
        8
    shell:
        """
        Rscript --vanilla {params.annotateclustersscript} \
            -b {input} \
            -g {params.gff3} \
            -t {threads} \
            > {log} 2>&1
        """

# ==========
# All Quantseq reads to generate count table
# ==========

# Then trim off the polyA tail and map
rule mapStar:
    input:
        fastq="results/cutadapt/{sample}_trimmed.fastq.gz"
    output:
        polyAtrimmedfastq=temp("results/mapped/{sample}.polya.trimmed.fastq.gz"),
        bam="results/mapped/{sample}.Aligned.sortedByCoord.out.bam",
        bai="results/mapped/{sample}.Aligned.sortedByCoord.out.bam.bai",
    threads:
        8
    params:
        star_index=config['star_index'],
        outprefix="results/mapped/{sample}.",
        cluster="-J mapStar -N 1 -c 8 --mem-per-cpu=4GB -t 24:00:00 -o logs/mapStar.{sample}.%A.log"
    shell:
        """
        cutadapt -j {threads} -m 18 --no-indels -e 0 -a "A{{1000}}" -o {output.polyAtrimmedfastq} {input.fastq}

        STAR --runThreadN {threads} \
        --genomeDir {params.star_index} --genomeLoad NoSharedMemory \
        --readFilesIn {input.fastq} --readFilesCommand zcat \
        --outFileNamePrefix {params.outprefix} \
        --sjdbScore 1 --alignSJoverhangMin 8 --alignSJDBoverhangMin 1 \
        --outFilterMultimapNmax 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverReadLmax 0.04 \
        --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 \
        --outFilterType BySJout --twopassMode Basic \
        --outSAMattributes All --outSAMstrandField intronMotif \
        --outSAMtype BAM SortedByCoordinate --limitBAMsortRAM 60000000000 \
        --quantMode GeneCounts

        samtools index -@ {threads} {output.bam}
        """

# Create RPM normalised bigwig for IGV
rule createbigwig:
    input:
        "results/mapped/{sample}.Aligned.sortedByCoord.out.bam"
    output:
        bigwig_pos="results/coverage/{sample}_plus.bigwig",
        bigwig_neg="results/coverage/{sample}_minus.bigwig",
        bg_pos=temp("results/coverage/{sample}.Signal.Unique.str1.out.bg"),
        bg_neg=temp("results/coverage/{sample}.Signal.Unique.str2.out.bg"),
        bg_multi_pos=temp("results/coverage/{sample}.Signal.UniqueMultiple.str1.out.bg"),
        bg_multi_neg=temp("results/coverage/{sample}.Signal.UniqueMultiple.str2.out.bg")
    params:
        outprefix="results/coverage/{sample}.",
        fai=config['fai'],
        cluster="-J createbigwig -N 1 -c 8 --mem-per-cpu=4GB -t 24:00:00 -o logs/createbigwig.{sample}.%A.log"
    threads:
        8
    shell:
        """
        STAR --runThreadN {threads} --runMode inputAlignmentsFromBAM --inputBAMfile {input} --outWigType bedGraph --outWigStrand Stranded --outWigNorm RPM --outFileNamePrefix {params.outprefix}
        bedSort {output.bg_pos} {output.bg_pos}
        bedSort {output.bg_neg} {output.bg_neg}
        bedGraphToBigWig {output.bg_pos} {params.fai} {output.bigwig_pos}
        bedGraphToBigWig {output.bg_neg} {params.fai} {output.bigwig_neg}
        """

rule createCountTable:
    input:
        pas="results/mergedclusters/polyAclusters.unique.annotated.bed",
        bam="results/mapped/{sample}.Aligned.sortedByCoord.out.bam",
    output:
        polyacount="results/counts/{sample}.polyacount.bed.gz",
        bed=temp("results/counts/{sample}.Aligned.sortedByCoord.out.bed"),
        polyabedgraph="results/counts/{sample}.polyacount.bedgraph.gz",
    params:
        clusterdist=config['clusterdist'],
        cluster="-J createCountTable -N 1 -c 1 --mem=16G -t 12:00:00 -o logs/createCountTable.{sample}.%A.log"
    shell:
        """
        # First convert BAM to BED for window
        bedtools bamtobed -split -i {input.bam} > {output.bed}

        # Then get non polyA read counts within a cluster distance window upstream of the polyA cluster
        bedtools window -l {params.clusterdist} -r 0 -sw -sm -c -a {input.pas} -b {output.bed} | pigz > {output.polyacount}

        # Bedgraphs for visualisation
        awk '{{OFS="\t"}}{{if($6 == "+") {{print $1, $2, $3, $5}} else {{print $1, $2, $3, -$5}}}}' {output.polyacount} |
        sort -k1,1 -k2,2n | pigz > {output.polyabedgraph}
        """

# ==========
# DRIMSeq analysis
# ==========

# Function to define combined input for drimseq rule
def drimseq_inputs(wildcards):
    files = expand("results/counts/{sample}.polyacount.bed.gz", sample = config["samples"])
    return files

rule drimseq:
    input:
        counttables=drimseq_inputs,
        pas="results/mergedclusters/polyAclusters.unique.annotated.bed",
    output:
        "results/drimseq/{mutant}.d.rds"
    log:
        "results/drimseq/{mutant}.rlog"
    threads:
        8
    params:
        mutant="{mutant}",
        cluster="-J drimseq -N 1 -c 8 --mem=32G -t 12:00:00 -o logs/drimseq.{mutant}.%A.log"
    run:
        counttables = ','.join(input.counttables)
        shell('scripts/drimseq.R {params.mutant} {input.pas} {counttables} {output} {threads} > {log} 2>&1')

# Function to define combined input for report rule
def report_inputs(wildcards):
    files = expand("results/drimseq/{mutant}.d.rds", mutant = config["mutants"])
    return files

rule report:
    input:
        rds=report_inputs,
        pas="results/mergedclusters/polyAclusters.unique.annotated.bed",
    output:
        report="results/quantseq_report.html",
        reportcache=temp(directory("results/quantseq_report_files")),
        # polyasiteoverlap="results/plots/polyAsite_overlap.pdf"
    params:
        polyasite2=config['polyasite2'],
        cluster="-J report -N 1 -c 8 --mem=32G -t 12:00:00 -o logs/report.%A.log"
    script:
        "scripts/report.R"